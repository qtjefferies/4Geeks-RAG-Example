{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.1.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import PyPDF2\n",
    "import openai\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import os\n",
    "from tiktoken import get_encoding\n",
    "from dotenv import load_dotenv\n",
    "#%pip install scikit-learn\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load OPEN AI Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API Key from environment variable\n",
    "# Open AI (LLM to process text)\n",
    "# Pinecone is database where vectors are actually stored\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY_API\")\n",
    "client = openai.OpenAI(api_key=os.getenv(\"OPENAI_KEY_API\"))\n",
    "\n",
    "# Initialize Pinecone using the Pinecone class\n",
    "# pc = Pinecone(api_key=pinecone_api_key)\n",
    "print(os.getenv(\"OPENAI_KEY_API\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SEC API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Embeddings/Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings using the new OpenAI API\n",
    "def get_embedding(text, engine=\"text-embedding-ada-002\"):\n",
    "    response = openai.embeddings.create(input=[text], model=engine)\n",
    "    embedding = response.data[0].embedding\n",
    "    embedding = np.array(embedding).reshape(1, -1)  # Ensure the embedding is a 2D array\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Vector Database to Local Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store vectors in local memory\n",
    "local_vector_store = {}\n",
    "\n",
    "# Function to add chunks to the local vector store\n",
    "def upload_chunks_to_local_memory(text_chunks):\n",
    "    for idx, chunk in enumerate(text_chunks):\n",
    "        embedding = get_embedding(chunk)\n",
    "        local_vector_store[f\"chunk_{idx}\"] = {\n",
    "            \"embedding\": embedding,\n",
    "            \"text\": chunk\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Text from PDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with open(pdf_file, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk text into smaller pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chunk the text into smaller pieces\n",
    "def chunk_text(text, chunk_size=1000):\n",
    "    encoding = get_encoding(\"cl100k_base\")  # Tokenizer model\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size)]\n",
    "    text_chunks = [encoding.decode(chunk) for chunk in chunks]\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Vectors to Pinecone if storing in Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to add chunks to the Pinecone vector database\n",
    "# def upload_chunks_to_pinecone(text_chunks):\n",
    "#     for idx, chunk in enumerate(text_chunks):\n",
    "#         embedding = get_embedding(chunk)\n",
    "#         index.upsert([(f\"chunk_{idx}\", embedding, {\"text\": chunk})])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change Question into a Vector to compare to the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    # Get the embedding of the question\n",
    "    question_embedding = get_embedding(question)\n",
    "    \n",
    "    # Verify that the embedding has the correct number of dimensions (1536)\n",
    "    if len(question_embedding) != 1536:\n",
    "        raise ValueError(f\"Embedding size is incorrect: {len(question_embedding)} dimensions found, expected 1536.\")\n",
    "    \n",
    "    # Reshape the question embedding to 2D\n",
    "    question_embedding = np.array(question_embedding).reshape(1, -1)\n",
    "    \n",
    "    # Query the local vector store\n",
    "    result = sorted(\n",
    "        local_vector_store.values(),\n",
    "        key=lambda x: cosine_similarity(np.array(x['embedding']).reshape(1, -1), question_embedding)[0][0],\n",
    "        reverse=True\n",
    "    )[:5]\n",
    "    \n",
    "    # Use OpenAI to generate an answer based on retrieved chunks\n",
    "    context = \" \".join([match['text'] for match in result])\n",
    "    \n",
    "    # Updated OpenAI API call for chat models using `ChatCompletion.create` method\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": f\"You are a stock Hedge Fund manager offering investment recommendation. Based on the following context: {context}, answer the question: {question}\"}\n",
    "        ],\n",
    "        max_tokens=250\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting text from the PDF, chunking it, and Uploading Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Extract text from the PDF\n",
    "pdf_text = extract_text_from_pdf('NVIDIAAn.pdf')\n",
    "\n",
    "# Chunk the text\n",
    "chunks = chunk_text(pdf_text)\n",
    "\n",
    "# Upload the chunks to Pinecone\n",
    "# upload_chunks_to_pinecone(chunks)\n",
    "\n",
    "# Upload Chunks to local store\n",
    "upload_chunks_to_local_memory(chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Model with Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA's Q1 FY2024 revenue stands at $7.19 billion, which is a decrease of 13% year-over-year (Y/Y) but an increase of 19% compared to the previous quarter. The company's Non-GAAP earnings per diluted share were $1.09, down 20% from the previous year but up 24% from the previous quarter. \n",
      "\n",
      "The results show that despite a yearly revenue dip, NVIDIA maintains strong quarterly growth. The positive forward-looking statement of an expected revenue of $11.00 billion for Q2 FY2024 also shows promise for the company's future. Moreover, the company's solid performance in the data center sector, a ramp-up of supply to meet increasing demands, and its positive positioning within the AI technology space can also act as positive indicators for investors.\n",
      "\n",
      "Based on the financial performance and future outlook, I would recommend a \"BUY\" status for NVIDIA. The company's strategic positioning, strong demand in the AI and data center sectors, improving operating margin, and positive revenue forecast for the upcoming quarter make it an attractive investment. However, investors should monitor the impact of semiconductor shortages on their future performance, as this could potentially affect the company's supply chain and overall growth.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"What is NVIDIA's revenue and Non-GAAP performance? Whats your buy, sell, hold recommendation and why?\"\n",
    "answer = ask_question(question)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
