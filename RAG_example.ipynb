{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import Dependencies\n",
    "\n",
    "import PyPDF2\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pinecone\n",
    "import os\n",
    "from tiktoken import get_encoding\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "PineconeConfigurationError",
     "evalue": "You haven't specified an Api-Key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPineconeConfigurationError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize Pinecone using the Pinecone class\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m pc \u001b[38;5;241m=\u001b[39m \u001b[43mPinecone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpinecone_api_key\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pinecone/control/pinecone.py:205\u001b[0m, in \u001b[0;36mPinecone.__init__\u001b[0;34m(self, api_key, host, proxy_url, proxy_headers, ssl_ca_certs, ssl_verify, config, additional_headers, pool_threads, index_api, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m config\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m \u001b[43mPineconeConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxy_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxy_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_ca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_ca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mssl_verify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_verify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenapi_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing openapi_config is no longer supported. Please pass settings such as proxy_url, proxy_headers, ssl_ca_certs, and ssl_verify directly to the Pinecone constructor as keyword arguments. See the README at https://github.com/pinecone-io/pinecone-python-client for examples.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pinecone/config/pinecone_config.py:29\u001b[0m, in \u001b[0;36mPineconeConfig.build\u001b[0;34m(api_key, host, additional_headers, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIgnoring PINECONE_ADDITIONAL_HEADERS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mConfigBuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43madditional_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madditional_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pinecone/config/config.py:58\u001b[0m, in \u001b[0;36mConfigBuilder.build\u001b[0;34m(api_key, host, proxy_url, proxy_headers, ssl_ca_certs, ssl_verify, additional_headers, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m source_tag \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(SOURCE_TAG, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m api_key:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified an Api-Key.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m host:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PineconeConfigurationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou haven\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt specified a host.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mPineconeConfigurationError\u001b[0m: You haven't specified an Api-Key."
     ]
    }
   ],
   "source": [
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set OpenAI API Key from environment variable\n",
    "openai.api_key = os.getenv(\"OPENAI_KEY\")\n",
    "pinecone_api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_KEY\"))\n",
    "\n",
    "# Initialize Pinecone using the Pinecone class\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the index exists, otherwise create one\n",
    "index_name = \"rag-example\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,  # Your embedding dimensions\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\",  # You specified AWS\n",
    "            region=\"us-east-1\"  # Your region\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Connect to the existing index\n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract text from the PDF\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    with open(pdf_file, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to chunk the text into smaller pieces\n",
    "def chunk_text(text, chunk_size=1000):\n",
    "    encoding = get_encoding(\"cl100k_base\")  # Tokenizer model\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = [tokens[i:i + chunk_size] for i in range(0, len(tokens), chunk_size)]\n",
    "    text_chunks = [encoding.decode(chunk) for chunk in chunks]\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings using the new OpenAI API\n",
    "def get_embedding(text, engine=\"text-embedding-ada-002\"):\n",
    "    response = openai.embeddings.create(input=[text], model=engine)\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add chunks to the Pinecone vector database\n",
    "def upload_chunks_to_pinecone(text_chunks):\n",
    "    for idx, chunk in enumerate(text_chunks):\n",
    "        embedding = get_embedding(chunk)\n",
    "        index.upsert([(f\"chunk_{idx}\", embedding, {\"text\": chunk})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(question):\n",
    "    # Get the embedding of the question\n",
    "    question_embedding = get_embedding(question)\n",
    "    \n",
    "    # Verify that the embedding has the correct number of dimensions (1536)\n",
    "    if len(question_embedding) != 1536:\n",
    "        raise ValueError(f\"Embedding size is incorrect: {len(question_embedding)} dimensions found, expected 1536.\")\n",
    "    \n",
    "    # Query the Pinecone vector database\n",
    "    result = index.query(vector=question_embedding, top_k=5, include_metadata=True)\n",
    "    \n",
    "    # Use OpenAI to generate an answer based on retrieved chunks\n",
    "    context = \" \".join([match['metadata']['text'] for match in result['matches']])\n",
    "    \n",
    "    # Updated OpenAI API call for chat models using `ChatCompletion.create` method\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Based on the following context: {context}, answer the question: {question}\"}\n",
    "        ],\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    # Return the assistant's answer\n",
    "    return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract text from the PDF\n",
    "pdf_text = extract_text_from_pdf('pvyn1u.pdf')\n",
    "\n",
    "# Chunk the text\n",
    "chunks = chunk_text(pdf_text)\n",
    "\n",
    "# Upload the chunks to Pinecone\n",
    "upload_chunks_to_pinecone(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What's the climax of the novel? Ah, that's a great question! The climax is like the big explosion at the end of a fireworks show, you know? It's when everything comes together, like the punchline of a really long joke. In \"The Midnight Feast\" by Lucy Foley, the climax occurs when all the suspense, the secrets, and the drama lead to that intense moment on the cliffs. Francesca and Eddie have this dramatic confrontation, and it's all happening amid the aftermath of the fire and everyone's shady past coming into play. It's the point where you're on the edge of your seat, and you just can't look away because everything is hitting the fan, and you're thinking, \"Wow, this is it. This is the moment we've been\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "question = \"What is the climax of the novel?\"\n",
    "answer = ask_question(question)\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
